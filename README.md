# ëª½íƒ€ì£¼ ê·¸ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ Text to Montage

ì‚¬ëŒì— ëŒ€í•œ ë¬˜ì‚¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª½íƒ€ì£¼ ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” [KoDALLE](https://github.com/KR-HappyFace/KoDALLE) ê¸°ë°˜ ëª¨ë¸

| Text | Generated montage |
| --- | --- |
| ë³¼ì´ ë„“ì€ ê³„ë€í˜• ì–¼êµ´ì´ë©° ì•ë¨¸ë¦¬ê°€ ì´ë§ˆì˜ ì–‘ìª½ ëì„ ê°€ë¦¬ê³  ìˆì–´ ëª¨ì–‘ì€ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤.   ì˜¤ë¥¸ìª½ í„±ì˜ ê°ì§„ ë¶€ë¶„ì´ ì™¼ìª½ì— ë¹„í•´ ì•„ë˜ë¡œ ë‚´ë ¤ì™€ ìˆê³  ì™¼ìª½ì€ ì•½ê°„ ì™„ë§Œí•œ í˜•íƒœì´ë‹¤.  í„±ëìœ¼ë¡œ ë‚´ë ¤ì˜¤ëŠ” í„±ëª¨ì–‘ì€ ì•½ê°„ ë‘¥ê·¼í˜•ìœ¼ë¡œ ë³´ì¸ë‹¤. ì™¼ìª½ì˜ ë³¼ì´ ë” í‰í‰í•˜ê³  ë„“ì€ í¸ì´ë‹¤. | ![](assets/output1.png) |
| ì´ë§ˆë¼ì¸ ê°€ìš´ë°ê°€ ì•„ë˜ë¡œ ì‚´ì§ ë‚´ë ¤ì™€ ìˆì–´ Mëª¨ì–‘ì„ ë„ê³  ìˆìœ¼ë©° ê°€ë¥´ë§ˆì˜ êµ¬ë¶„ ì—†ì´ ëª¨ë‘ ì˜¬ë ¤ì ¸ ìˆìœ¼ë‚˜ í—¤ì–´ë¼ì¸ ê°€ìš´ë°ì—ì„œ ì‚´ì§ ì˜¤ë¥¸í¸ìœ¼ë¡œ í—¤ì–´ì ¤ì„ ë°”ë¥¸ ë“¯ ì¡°ê¸ˆ ë‚˜ë‰œ ëª¨ìŠµë„ ë³´ì¸ë‹¤. ì˜†ë¨¸ë¦¬ëŠ” ì™¼ìª½ì€ ê·“ë°”í€´ ì‹œì‘ ì§€ì ê¹Œì§€ ë‚´ë ¤ì™€ ìˆìœ¼ë©° ì˜¤ë¥¸ìª½ì€ ê·€ì— ë°”ë¡œ ë‹¿ì„ ë“¯ ë‚´ë ¤ì™€ ìˆë‹¤. | ![](assets/output2.png) |
| ê°ì§„ ì–¼êµ´ì— ê´‘ëŒ€ëŠ” ë§¤ë„ëŸ½ê³  í° ë³¼ì„ ê°€ì§€ê³  ìˆì–´ ì•½ê°„ í›„ë•í•œ ì¸ìƒì„ ì¤€ë‹¤. ëˆˆë§¤ì˜ ë¼ì¸ì´ ë¶€ë“œëŸ¬ì›Œ ë”°ëœ»í•œ ì¸ìƒì„ ì£¼ë©° ëˆ„êµ¬ì—ê²Œë‚˜ ì¹œì ˆì„ ë² í’€ ê²ƒ ê°™ì€ ì¸ë¬¼ì´ë‹¤. ì…ë§¤ê°€ ë¶€ë“œëŸ½ê³  ì•½ê°„ ì–‡ì€ ë“¯í•´ì„œ ë§í•˜ê¸° ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ ê°™ê¸°ë„ í•˜ë‹¤. | ![](assets/output3.png) |
| ëˆˆë§¤ì™€ ì…ë§¤ê°€ ë¶€ë“œëŸ½ê³  ë¯¸ì†Œì§“ê³  ìˆëŠ” ëª¨ìŠµìœ¼ë¡œ  ì„±í’ˆì´ ì°©í•˜ê³  ìœ í•œ ì‚¬ëŒìœ¼ë¡œ ë³´ì¸ë‹¤. ì•½ê°„ ì—¬ì„±ìŠ¤ëŸ¬ìš´ ì„±ê²©ì¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ìœ¼ë©° ëˆ„êµ¬ì—ê²Œë‚˜ ì¹œì ˆí•˜ê³  ì–´ì§„ ëª¨ìŠµìœ¼ë¡œ ëŒ€í•´ì£¼ëŠ” í¸ì•ˆí•œ ì‚¬ëŒìœ¼ë¡œ ëŠê»´ì§„ë‹¤. | ![](assets/output4.png) |
| ëˆˆì´ ì‘ê³  ì—¬ì„±ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° ì…ìˆ ì€ ë„í†°í•˜ë‹¤. | ![](assets/output5.png) |

## Dataset

[í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ì˜ ê°€ìƒ ì¸ë¬¼ ëª½íƒ€ì£¼ - AIHub](https://www.aihub.or.kr/aihubdata/data/view.do?dataSetSn=618)

![https://www.aihub.or.kr/aihubdata/data/view.do?dataSetSn=618](assets/dataset.jpg)

## Training Process

1. Download dataset from above
2. Preprocess dataset using [preprocess.ipynb](preprocess.ipynb)
3. Train [VQGAN](https://github.com/kairess/taming-transformers)
4. Extract `klue/roberta-large` models (run [extract_emb_models.py](extract_emb_models.py))
5. Train KoDALLE

## Inference Pipeline

- [test.ipynb](test.ipynb)
- [Gradio App](app.py)

## Wandb Logs

- VQGAN https://wandb.ai/kairess/DALLE-Couture?workspace=user-kairess
- KoDALLE https://wandb.ai/kairess/optimization?workspace=user-kairess

---

# KoDALLE

[![Generic badge](https://img.shields.io/badge/ğŸ“„-Presentation-blue.svg)](https://github.com/KR-HappyFace/KoDALLE/blob/main/README.pdf) [![Wandb Log](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/happyface-boostcamp/final)

[![image-20211227151557604](assets/README/image-20211227151557604.png)](https://github.com/KR-HappyFace/KoDALLE/blob/main/README.pdf)

**Training DALLE from scratch, utilizing target language's PLMs' token embedding layer and position embedding layer as text encoder.**

### Background

[ğŸ“‚ For the project details, please refer to README.pdf](https://github.com/KR-HappyFace/KoDALLE/blob/main/README.pdf)

- Training DALLE model from scratch demands large size paired dataset of images and captions. For example, OpenAI DALLE is trained with more than 250 million text-image pairs for the training.
- If the dataset isnâ€™t large enough or is limited to specific domains, number of vocabularies in the trained DALLE model are insufficient. For instance, 1 million text captions of K-Fashion dataset only consists of more or less than 300 tokens.
- Therefore, inferencing from such DALLE models could be problematic if the given sentence query is unconnected to the originally trained captionsâ€™ text dataset.

### KoDALLE's Result on Small Size Fashion Dataset

|                        |      OpenAIâ€™s DALLE       |           KoDALLE of HappyFace            |
| :--------------------: | :-----------------------: | :---------------------------------------: |
| **Train Dataset Size** |     250 Million Pairs     |             0.8 Million Pairs             |
|      **#Params**       |        12 Billion         |                428 Million                |
|      **#Layers**       |         64 Layers         |                 16 Layers                 |
| **Computing Resource** |     1024 x V100 16GB      |               1 x V100 32GB               |
|    **Text Encoder**    | 16384 Vocab x 512 Dim BPE | 32000 Vocab x 1024 Dim klue/roberta-large |
|   **Image Encoder**    |           VQVAE           |                   VQGAN                   |
|     **Optimizer**      |           AdamW           |                   AdamW                   |
|   **Learning Rate**    |          4.5e-5           |                  3.0e-5                   |
|    **Weight Decay**    |          4.5e-3           |                  3.0e-3                   |
|    **LR Scheduler**    |     ReduceLROnPlateau     |                     -                     |

**The team constructed Text to Fashion Design DALLE model in Korean language with less than 100k text-image sampled pairs.**

|                     |                                                                                                                                                                                                                      |
| :-----------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|     **Caption**     | í•˜ì˜ì—ì„œ ìƒ‰ìƒì€ ìŠ¤ì¹´ì´ë¸”ë£¨ì´ë‹¤. ìƒì˜ì—ì„œ ê¸°ì¥ì€ ë¡±ì´ë‹¤. ìƒ‰ìƒì€ í™”ì´íŠ¸ì´ë‹¤. ì¹´í…Œê³ ë¦¬ëŠ” ë¸”ë¼ìš°ìŠ¤ì´ë‹¤. ë””í…Œì¼ì—ëŠ” ì…”ë§ì´ë‹¤. ì†Œë§¤ê¸°ì¥ì€ ë°˜íŒ”ì´ë‹¤. ì†Œì¬ì—ëŠ” ì‹¤í¬ì´ë‹¤. í”„ë¦°íŠ¸ì—ëŠ” ë¬´ì§€ì´ë‹¤. ë„¥ë¼ì¸ì€ ë¸Œì´ë„¥ì´ë‹¤. í•ì€ ë…¸ë©€ |
| **Generated Image** |                                                              <img height="250" width="200" alt="image" src="assets/README/image-20211227152252313.png">                                                              |

|                     |                                                                                                                   |
| :-----------------: | :---------------------------------------------------------------------------------------------------------------: |
|     **Caption**     | ì•„ìš°í„°ëŠ” ìƒ‰ìƒì´ ì¹´í‚¤ ì†Œì¬ê°€ ìš°ë¸ í•ì´ ë£¨ì¦ˆì¸ ì½”íŠ¸ì´ë‹¤. í•˜ì˜ëŠ” ìƒ‰ìƒì´ ë„¤ì´ë¹„ ì†Œì¬ê°€ ë°ë‹˜ í•ì´ ìŠ¤í‚¤ë‹ˆì¸ ì²­ë°”ì§€ì´ë‹¤. |
| **Generated Image** |            <img height="250" width="200" alt="image" src="assets/README/image-20211227152034538.png">             |

|                     |                                                                                                                                                                                                                         |
| :-----------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|     **Caption**     | í•˜ì˜ì—ì„œ ê¸°ì¥ì€ ë°œëª©ì´ë‹¤. ìƒ‰ìƒì€ ë¸”ë£¨ì´ë‹¤. ì¹´í…Œê³ ë¦¬ëŠ” ìŠ¤ì»¤íŠ¸ì´ë‹¤. ì†Œì¬ì—ëŠ” ë°ë‹˜ì´ë‹¤. í•ì€ ì™€ì´ë“œì´ë‹¤. ìƒì˜ì—ì„œ ìƒ‰ìƒì€ í™”ì´íŠ¸ì´ë‹¤. ì¹´í…Œê³ ë¦¬ëŠ” ë¸”ë¼ìš°ìŠ¤ì´ë‹¤. ë””í…Œì¼ì—ëŠ” ì…”ë§ì´ë‹¤. ì†Œë§¤ê¸°ì¥ì€ ë°˜íŒ”ì´ë‹¤. ì†Œì¬ì—ëŠ” ìš°ë¸ì´ë‹¤. |
| **Generated Image** |                                                               <img height="250" width="200" alt="image" src="assets/README/image-20211227152127324.png">                                                                |

|                     |                                                                                                                                                                                                                                                                       |
| :-----------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|     **Caption**     | ìƒì˜ì—ì„œ ê¸°ì¥ì€ ë…¸ë©€ì´ë‹¤. ìƒì˜ì—ì„œ ìƒ‰ìƒì€ í™”ì´íŠ¸ì´ë‹¤. ìƒì˜ì—ì„œ ì„œë¸Œìƒ‰ìƒì€ ë¸”ë™ì´ë‹¤. ìƒì˜ì—ì„œ ì¹´í…Œê³ ë¦¬ëŠ” í‹°ì…”ì¸ ì´ë‹¤. ìƒì˜ì—ì„œ ì†Œë§¤ê¸°ì¥ì€ ë°˜íŒ”ì´ë‹¤. ìƒì˜ì—ì„œ ì†Œì¬ì—ëŠ” ì €ì§€ì´ë‹¤. ìƒì˜ì—ì„œ í”„ë¦°íŠ¸ì—ëŠ” ë ˆí„°ë§ì´ë‹¤. ìƒì˜ì—ì„œ ë„¥ë¼ì¸ì€ ë¼ìš´ë“œë„¥ì´ë‹¤. ìƒì˜ì—ì„œ í•ì€ ë£¨ì¦ˆì´ë‹¤. |
| **Generated Image** |                                                                                      <img height="250" width="200" alt="image" src="assets/README/image-20211227152337621.png">                                                                                       |

### Methodology

Experimentations were conducted with the following Korean Transformers Modelsâ€™ embedding layers. The team selected klue/roberta-large as baseline in the repository considering the size of the model.

- **[klue/roberta-large](https://huggingface.co/klue/roberta-large): Vocab Size of 32000, Embedding Dimension of 1024.**
- [KoGPT Trinity of SKT](https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5): Vocab Size of 51200, Embedding Dimension of 1920.
- [KoGPT of Kakao Brain](https://huggingface.co/kakaobrain/kogpt): Vocab Size of 64512, Embedding Dimension of 4096.

KoDALLE with klue/roberta-large's wpe and wte were trained on 32GB V100 GPU environment. Hyperparams related to the DALLE's model size are following.

```
'BATCH_SIZE': 40
'DEPTH': 16
'TEXT_SEQ_LEN': 128
'VOCAB_SIZE': 32000
'MODEL_DIM': 1024
'ATTN_TYPES': 'full'
'DIM_HEAD': 64
'HEADS': 8
```

- DALLE model is composed on [lucidrain's DALLE-pytorch](https://github.com/lucidrains/DALLE-pytorch)
- Image encoder is constructed based on [VQGAN(Taming Transformers)](https://github.com/CompVis/taming-transformers#training-on-custom-data)

### Significance

- Offers promising result for training from scratch on specific domains with small size dataset.
- Introduces solution for domain specific DALLE & CLIP models to be robust on input sentence.
- Recommends adequate text-to-image model size for given computation resource.
- Suggests effortless method of creating DALLE & CLIP model for own languages if pretrained language model is available.

---

### WIP

- [x] Add image-caption reranker(EfficientNet + Klue/roberta-large)
- [x] Model trained with 500k text-image pairs.
- [x] Modulize in python code.
- [x] Update Inference code.
- [ ] Update FID and IS metrics on test and validation dataset.

### Citations

```bibtex
@misc{ramesh2021zeroshot,
    title   = {Zero-Shot Text-to-Image Generation},
    author  = {Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
    year    = {2021},
    eprint  = {2102.12092},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

```

```bibtex
@misc{esser2021taming,
    title   = {Taming Transformers for High-Resolution Image Synthesis},
    author  = {Patrick Esser and Robin Rombach and BjÃ¶rn Ommer},
    year    = {2021},
    eprint  = {2012.09841},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}
```
